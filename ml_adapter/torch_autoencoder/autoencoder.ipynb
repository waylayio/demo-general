{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46523964-f381-46ff-b009-76b32cdc3b00",
   "metadata": {},
   "source": [
    "# A pytorch ML adapter demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a0400-976b-4e31-b681-e09d61d2881d",
   "metadata": {},
   "source": [
    " 1. [Pytorch](#pytorch) model example.\n",
    " 2. Create [Adapter](#adapter).\n",
    " 3. How to create a [Webscript](#webscript).\n",
    " 4. How to create a [Plug](#plug)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd854b-9a6e-4bac-9650-5d86b3ea56d5",
   "metadata": {},
   "source": [
    "#### Preamble\n",
    "Demo of a relatively small pytorch model.\n",
    "This notebook uses the [ml_adapter_torch](../../env/ml_adapter_torch) dependencies.\n",
    "To start: \n",
    "```\n",
    "bin/jupyter_notebook env/ml_adapter_torch ml_adapter/torch_autoencoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d623cc-fad6-4d2c-9e43-8bb9ccde3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sdk profile used to connect\n",
    "PROFILE='_default_'\n",
    "LOG_LEVEL='INFO'\n",
    "MODEL_NAME='autoencoderV1'\n",
    "MODEL_VERSION='1.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfbefcf-84f8-40d2-9393-ed3988630147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup INFO logging to see http requests made.\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=LOG_LEVEL,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e989be6-88be-40c9-b80a-e77d5f152eb8",
   "metadata": {},
   "source": [
    "## 1. Pytorch example <a id=\"pytorch\"></a>\n",
    "\n",
    "A simple auto-encoder pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbe4087-26be-4945-8f1a-96fab99d3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b779cd6-2c39-4efa-95ef-6a8389ec7820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### `autoencoder.py` source"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">torch</span>\n",
       "\n",
       "<span class=\"k\">class</span><span class=\"w\"> </span><span class=\"nc\">AutoEncoder</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "<span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">        Create a simple AutoEncoder</span>\n",
       "<span class=\"sd\">        &quot;&quot;&quot;</span>\n",
       "        <span class=\"c1\"># Use an AutoEncoder and try to reconstruct both signals (the 20 samples back)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">),</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">encoded</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">decoded</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder</span><span class=\"p\">(</span><span class=\"n\">encoded</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">decoded</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{torch}\n",
       "\n",
       "\\PY{k}{class}\\PY{+w}{ }\\PY{n+nc}{AutoEncoder}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{+w}{        }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{        Create a simple AutoEncoder}\n",
       "\\PY{l+s+sd}{        \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "        \\PY{c+c1}{\\PYZsh{} Use an AutoEncoder and try to reconstruct both signals (the 20 samples back)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{20}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{ReLU}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{ReLU}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{20}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{encoded} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder}\\PY{p}{(}\\PY{n}{x}\\PY{p}{)}\n",
       "        \\PY{n}{decoded} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder}\\PY{p}{(}\\PY{n}{encoded}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{decoded}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import torch\n",
       "\n",
       "class AutoEncoder(torch.nn.Module):\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        \"\"\"\n",
       "        Create a simple AutoEncoder\n",
       "        \"\"\"\n",
       "        # Use an AutoEncoder and try to reconstruct both signals (the 20 samples back)\n",
       "        self.encoder = torch.nn.Sequential(\n",
       "            torch.nn.Linear(20, 10),\n",
       "            torch.nn.ReLU(),\n",
       "            torch.nn.Linear(10, 5),\n",
       "        )\n",
       "\n",
       "        self.decoder = torch.nn.Sequential(\n",
       "            torch.nn.Linear(5, 10),\n",
       "            torch.nn.ReLU(),\n",
       "            torch.nn.Linear(10, 20),\n",
       "        )\n",
       "\n",
       "    def forward(self, x):\n",
       "        encoded = self.encoder(x)\n",
       "        decoded = self.decoder(encoded)\n",
       "        return decoded"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we saved our model class in a `autoencoder.py` file\n",
    "from IPython.display import Code, Markdown\n",
    "display(Markdown(f'### `autoencoder.py` source'))\n",
    "display(Code(filename='autoencoder.py'))\n",
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5409ee2-ffb0-450b-91a6-9be5b857c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some pretrained weights\n",
    "weights_path = 'AutoEncoderWeights.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a7a6e6-ece7-49d3-8bba-a128ebc621c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load(weights_path, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f74982-aea0-4d08-8ef7-71c7fec68a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1458, -0.8573, -0.4810,  1.3070, -1.6287, -2.4500, -2.0896,  0.5397,\n",
       "        -0.2585,  0.6075, -0.3521,  0.5024, -0.0205,  0.2033,  0.6291,  0.6521,\n",
       "        -1.6579,  0.0916, -0.2855, -1.4349])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = torch.randn(20, dtype=torch.float32)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cef5213-7a07-4360-80b1-6bd352a188a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3229, -0.3600, -0.3960, -0.3263, -0.3969, -0.4243, -0.4064, -0.3829,\n",
       "        -0.4136, -0.2749, -0.3954, -0.3799, -0.3340, -0.3710, -0.3791, -0.3988,\n",
       "        -0.3101, -0.4098, -0.4013, -0.3952], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a model inference:\n",
    "preds = model(x_data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc56c20c-e56c-476b-ba70-27e40a479b1f",
   "metadata": {},
   "source": [
    "## 2. The adapter <a id=\"adapter\"></a>\n",
    "The `V1TorchAdapter` from the `ml_adapter.torch` module wraps our model in a script that can be used as a waylay webscript or plug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7023e2eb-4ebb-4f5e-a436-5e11b07222e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a local archive location\n",
    "ARCHIVE_LOC = 'autoencoder-pytorch'\n",
    "# make sure its empty\n",
    "!rm -fr autoencoder-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc2c179-9eb8-4406-ba6a-ef38f6786336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_adapter.torch import V1TorchAdapter\n",
    "# create an ML adapter to wrap our model\n",
    "# by using a `weights.pt` postfix we are storing only the weights when serializing the model\n",
    "MODEL_PATH='model-weights.pt'\n",
    "adapter = V1TorchAdapter(model=model, model_path='model-weights.pt', location=ARCHIVE_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47bc96ed-9f3c-4958-a718-4eb7b18735d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[-0.3229316771030426,\n",
       "   -0.36001601815223694,\n",
       "   -0.3960452079772949,\n",
       "   -0.32631662487983704,\n",
       "   -0.3968595266342163,\n",
       "   -0.4243429899215698,\n",
       "   -0.40644288063049316,\n",
       "   -0.3829203248023987,\n",
       "   -0.41355741024017334,\n",
       "   -0.27493229508399963,\n",
       "   -0.3954361081123352,\n",
       "   -0.3798944652080536,\n",
       "   -0.3340391516685486,\n",
       "   -0.3709794878959656,\n",
       "   -0.37912052869796753,\n",
       "   -0.3987690806388855,\n",
       "   -0.3101225197315216,\n",
       "   -0.40983518958091736,\n",
       "   -0.40134039521217346,\n",
       "   -0.3952208459377289]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the adapter exposes your model with a REST-compatible interface\n",
    "result = await adapter.call({\"instances\": [ x_data.tolist() ]}) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c77d97-61a2-488c-8e07-8c894b7a8f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder.py <ml_adapter.base.assets.python.PythonScriptAsset>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because we store only weights, the adapter archive needs to now about autoencode model class\n",
    "# Its not recommended to store full serialized models, as these are more brittle with respect versions of python and torch\n",
    "await adapter.add_script('autoencoder.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4807ddc-7c5e-4e01-859c-202062ab690a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-weights.pt',\n",
       " 'webscript.json',\n",
       " 'requirements.txt',\n",
       " 'main.py',\n",
       " 'autoencoder.py']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await adapter.save()\n",
    "# have a look at ARCHIVE_LOC to see the stored assets\n",
    "list(a.path for a in adapter.assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9872aa-6cab-43ea-9fd4-87f1a43390fc",
   "metadata": {},
   "source": [
    "## 3. Deploying as webscript <a id=\"webscript\"></a>\n",
    "Tell the adapter to configure itself as a webscript: this generates a number of _assets_ that will be uploaded and define the webscript behaviour\n",
    "* a `webscript.json` _manifest_ file that defines the name, version, _runtime_, deploy settings, metadata ...\n",
    "* a `requirements.txt` package dependencies file\n",
    "* a `main.py` webscript script\n",
    "* additional scripts we added above, like the `autoencoder.py` and the `model-weights.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68556cd-921d-495d-93d1-a94c7897d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## configure any 'memory' or 'cpu' deploy settings \n",
    "deploy_overrides = {'limits' : { 'memory': '2G' }, 'requests' : { 'memory' : '1G' }}\n",
    "## configure the webscript to use our model\n",
    "adapter = adapter.as_webscript({\n",
    "    'name': MODEL_NAME, \n",
    "    'description':'pytorch autoencoder for caats', \n",
    "    'deploy' : deploy_overrides                                                                                          \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e75891d-87fc-4b58-925f-e779595a3b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-weights.pt',\n",
       " 'webscript.json',\n",
       " 'requirements.txt',\n",
       " 'main.py',\n",
       " 'autoencoder.py']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await adapter.save()\n",
    "list(a.path for a in adapter.assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c2ce077-f293-4c2f-9c6f-7784ddb3fdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># ml_adapter.torch.adapter.V1TorchAdapter model adapter</span>\n",
       "<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">os</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">starlette.requests</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">Request</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">starlette.responses</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">JSONResponse</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">starlette.exceptions</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">HTTPException</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">ml_adapter.torch.adapter</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">V1TorchAdapter</span>\n",
       "\n",
       "<span class=\"n\">MODEL_PATH</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">&#39;MODEL_PATH&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;model-weights.pt&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">MODEL_CLASS</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">&#39;MODEL_CLASS&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;autoencoder.AutoEncoder&#39;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Initialize the model adapter.</span>\n",
       "<span class=\"c1\"># Provide a `model` argument if you want to create/load the model yourself.</span>\n",
       "<span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">V1TorchAdapter</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">model_path</span><span class=\"o\">=</span><span class=\"n\">MODEL_PATH</span><span class=\"p\">,</span> <span class=\"n\">model_class</span><span class=\"o\">=</span><span class=\"n\">MODEL_CLASS</span>\n",
       "<span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Webscript handler</span>\n",
       "<span class=\"k\">async</span> <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">execute</span><span class=\"p\">(</span><span class=\"n\">request</span><span class=\"p\">:</span> <span class=\"n\">Request</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">method</span> <span class=\"o\">==</span> <span class=\"s1\">&#39;GET&#39;</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">JSONResponse</span><span class=\"p\">(</span><span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">openapi</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">method</span> <span class=\"o\">!=</span> <span class=\"s1\">&#39;POST&#39;</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">raise</span> <span class=\"n\">HTTPException</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">status_code</span><span class=\"o\">=</span><span class=\"mi\">405</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">detail</span><span class=\"o\">=</span><span class=\"s1\">&#39;This webscript only accepts `POST` calls.&#39;</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "    <span class=\"c1\"># use request body as input</span>\n",
       "    <span class=\"n\">request_json</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">request</span><span class=\"o\">.</span><span class=\"n\">json</span><span class=\"p\">()</span>\n",
       "    <span class=\"c1\"># call the model adapter using the V1</span>\n",
       "    <span class=\"n\">response_json</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">call</span><span class=\"p\">(</span><span class=\"n\">request_json</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">JSONResponse</span><span class=\"p\">(</span><span class=\"n\">response_json</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} ml\\PYZus{}adapter.torch.adapter.V1TorchAdapter model adapter}\n",
       "\\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{os}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{starlette}\\PY{n+nn}{.}\\PY{n+nn}{requests}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{Request}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{starlette}\\PY{n+nn}{.}\\PY{n+nn}{responses}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{JSONResponse}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{starlette}\\PY{n+nn}{.}\\PY{n+nn}{exceptions}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{HTTPException}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{ml\\PYZus{}adapter}\\PY{n+nn}{.}\\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{adapter}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{V1TorchAdapter}\n",
       "\n",
       "\\PY{n}{MODEL\\PYZus{}PATH} \\PY{o}{=} \\PY{n}{os}\\PY{o}{.}\\PY{n}{environ}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MODEL\\PYZus{}PATH}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZhy{}weights.pt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{n}{MODEL\\PYZus{}CLASS} \\PY{o}{=} \\PY{n}{os}\\PY{o}{.}\\PY{n}{environ}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MODEL\\PYZus{}CLASS}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{autoencoder.AutoEncoder}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Initialize the model adapter.}\n",
       "\\PY{c+c1}{\\PYZsh{} Provide a `model` argument if you want to create/load the model yourself.}\n",
       "\\PY{n}{adapter} \\PY{o}{=} \\PY{n}{V1TorchAdapter}\\PY{p}{(}\n",
       "    \\PY{n}{model\\PYZus{}path}\\PY{o}{=}\\PY{n}{MODEL\\PYZus{}PATH}\\PY{p}{,} \\PY{n}{model\\PYZus{}class}\\PY{o}{=}\\PY{n}{MODEL\\PYZus{}CLASS}\n",
       "\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Webscript handler}\n",
       "\\PY{k}{async} \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{execute}\\PY{p}{(}\\PY{n}{request}\\PY{p}{:} \\PY{n}{Request}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{if} \\PY{n}{request}\\PY{o}{.}\\PY{n}{method} \\PY{o}{==} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{GET}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}\n",
       "        \\PY{k}{return} \\PY{n}{JSONResponse}\\PY{p}{(}\\PY{n}{adapter}\\PY{o}{.}\\PY{n}{openapi}\\PY{p}{)}\n",
       "    \\PY{k}{if} \\PY{n}{request}\\PY{o}{.}\\PY{n}{method} \\PY{o}{!=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{POST}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:}\n",
       "        \\PY{k}{raise} \\PY{n}{HTTPException}\\PY{p}{(}\n",
       "            \\PY{n}{status\\PYZus{}code}\\PY{o}{=}\\PY{l+m+mi}{405}\\PY{p}{,}\n",
       "            \\PY{n}{detail}\\PY{o}{=}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{This webscript only accepts `POST` calls.}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "    \\PY{c+c1}{\\PYZsh{} use request body as input}\n",
       "    \\PY{n}{request\\PYZus{}json} \\PY{o}{=} \\PY{k}{await} \\PY{n}{request}\\PY{o}{.}\\PY{n}{json}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{c+c1}{\\PYZsh{} call the model adapter using the V1}\n",
       "    \\PY{n}{response\\PYZus{}json} \\PY{o}{=} \\PY{k}{await} \\PY{n}{adapter}\\PY{o}{.}\\PY{n}{call}\\PY{p}{(}\\PY{n}{request\\PYZus{}json}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{JSONResponse}\\PY{p}{(}\\PY{n}{response\\PYZus{}json}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "# ml_adapter.torch.adapter.V1TorchAdapter model adapter\n",
       "import os\n",
       "from starlette.requests import Request\n",
       "from starlette.responses import JSONResponse\n",
       "from starlette.exceptions import HTTPException\n",
       "from ml_adapter.torch.adapter import V1TorchAdapter\n",
       "\n",
       "MODEL_PATH = os.environ.get('MODEL_PATH', 'model-weights.pt')\n",
       "MODEL_CLASS = os.environ.get('MODEL_CLASS', 'autoencoder.AutoEncoder')\n",
       "\n",
       "# Initialize the model adapter.\n",
       "# Provide a `model` argument if you want to create/load the model yourself.\n",
       "adapter = V1TorchAdapter(\n",
       "    model_path=MODEL_PATH, model_class=MODEL_CLASS\n",
       ")\n",
       "\n",
       "# Webscript handler\n",
       "async def execute(request: Request):\n",
       "    if request.method == 'GET':\n",
       "        return JSONResponse(adapter.openapi)\n",
       "    if request.method != 'POST':\n",
       "        raise HTTPException(\n",
       "            status_code=405,\n",
       "            detail='This webscript only accepts `POST` calls.',\n",
       "        )\n",
       "    # use request body as input\n",
       "    request_json = await request.json()\n",
       "    # call the model adapter using the V1\n",
       "    response_json = await adapter.call(request_json)\n",
       "    return JSONResponse(response_json)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets have a look at the generated python webscript:\n",
    "display(Code(filename=f'{ARCHIVE_LOC}/main.py'))\n",
    "\n",
    "# You could adapt this script to have specific error handling or handling of request/response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d65e204-c421-4026-a337-330dcbeca22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:19:54 INFO     loading torch model weights from autoencoder-pytorch/model-weights.pt\n",
      "2025-01-21 17:19:54 INFO     creating torch model with class AutoEncoder\n",
      "2025-01-21 17:19:54 INFO     loading torch model weights from autoencoder-pytorch/model-weights.pt\n",
      "2025-01-21 17:19:54 INFO     creating torch model with class AutoEncoder\n"
     ]
    }
   ],
   "source": [
    "# once stored, the adapter can be restored later with\n",
    "adapter = await V1TorchAdapter(model_path='model-weights.pt', model_class=AutoEncoder, location=ARCHIVE_LOC).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9d9e482-cf73-4631-b94a-a732b158701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[model-weights.pt <ml_adapter.torch.adapter.TorchModelWeightsAsset>,\n",
       " webscript.json <ml_adapter.base.assets.manifest.WebscriptManifestAsset>,\n",
       " requirements.txt <ml_adapter.base.assets.python.PythonRequirementsAsset>,\n",
       " main.py <ml_adapter.base.assets.python.PythonScriptAsset>,\n",
       " autoencoder.py <ml_adapter.base.assets.python.PythonScriptAsset>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(adapter.assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e0183-cf8c-4225-965e-89b75b3c781d",
   "metadata": {},
   "source": [
    "### Uploading the webscript using the SDK\n",
    "To upload these assets and create a webscript, we need to call the [create webcript](https://docs.waylay.io/openapi/public/redocly/registry.html#tag/Webscripts/operation/create_webscripts) REST api. \n",
    "\n",
    "The code belows uses the `ml_tool` plugin to handle this.\n",
    "Alternatively you could call `await adapter.save_archive()`\n",
    "which creates an `autoencoder-pytorch.tar.gz` archive that you can upload as webscript with `curl` or using the waylay console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbb7b49c-cc60-4e8a-afae-a2908a6caf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waylay.sdk import WaylayClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecca79ac-ad09-43c4-876a-7a5e9fd7b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the SDK client\n",
    "client = WaylayClient.from_profile('staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb3be5d7-2bba-459d-bd88-e958ba9c4a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:19:54 INFO     HTTP Request: POST https://api-aws-dev.waylay.io/accounts/v1/tokens?grant_type=client_credentials \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 17:19:55 INFO     HTTP Request: DELETE https://api-aws-dev.waylay.io/registry/v2/webscripts/autoencoderV1 \"HTTP/1.1 202 Accepted\"\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "try:\n",
    "    ref = await client.registry.webscripts.remove_versions(MODEL_NAME)\n",
    "    await asyncio.sleep(5)\n",
    "except Exception as e:\n",
    "    print(f'nothing to delete? {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70434f0b-6bdc-4ca8-8214-0dd40ba5bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:20:05 INFO     HTTP Request: POST https://api-aws-dev.waylay.io/registry/v2/webscripts/?draft=false&comment=&async=true \"HTTP/1.1 202 Accepted\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': \"Building and deploying webscript 'autoencoderV1@0.0.1'\",\n",
       " '_links': {'event': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=verify&id=740799ef-d515-4704-8718-903851c9899e$6mcNQQ8pV1oC-frgiwTZL&children=true'},\n",
       "  'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/verify/740799ef-d515-4704-8718-903851c9899e$6mcNQQ8pV1oC-frgiwTZL'}},\n",
       " 'entity': {'createdBy': 'users/08e92c94-0a45-4f69-8405-3c2e46dd0cf9',\n",
       "  'createdAt': '2025-01-21T16:20:05.603Z',\n",
       "  'updatedBy': 'users/08e92c94-0a45-4f69-8405-3c2e46dd0cf9',\n",
       "  'updatedAt': '2025-01-21T16:20:05.615Z',\n",
       "  'status': 'pending',\n",
       "  'runtime': {'deprecated': False,\n",
       "   'upgradable': False,\n",
       "   'name': 'web-python3',\n",
       "   'version': '0.2.0'},\n",
       "  'deprecated': False,\n",
       "  'draft': False,\n",
       "  'webscript': {'name': 'autoencoderV1',\n",
       "   'version': '0.0.1',\n",
       "   'runtime': 'web-python3',\n",
       "   'metadata': {},\n",
       "   'private': True,\n",
       "   'allowHmac': True,\n",
       "   'deploy': {'limits': {'memory': '2G'}, 'requests': {'memory': '1G'}},\n",
       "   'tags': []},\n",
       "  'updates': [{'operation': 'create',\n",
       "    'at': '2025-01-21T16:20:05.615Z',\n",
       "    'by': 'users/08e92c94-0a45-4f69-8405-3c2e46dd0cf9',\n",
       "    'comment': '',\n",
       "    'jobs': ['740799ef-d515-4704-8718-903851c9899e$6mcNQQ8pV1oC-frgiwTZL',\n",
       "     '740799ef-d515-4704-8718-903851c9899e$y8Qxfc_eAH2BYdogYAe3H',\n",
       "     '740799ef-d515-4704-8718-903851c9899e$IGqkit2bCuxsobW9x2iKQ']}],\n",
       "  'secret': 'QdGMmM36DTe2X6q3dGyds0OwGUbuFGAMlKqW8zkiMfQ='}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = await client.ml_tool.create_webscript(adapter)\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e43e3769-ae89-42aa-94fa-c7ce3c91777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current status\n",
    "# ref = await client.registry.webscripts.get(MODEL_NAME,'0.0.1', response_type=dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eafa7599-93b2-47b3-bdaa-871666b6d025",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# when build/deployment fails, this performs a retry\n",
    "# ref = await client.registry.webscripts.rebuild(MODEL_NAME,'0.0.1', query={'ignoreChecks':True}, response_type=dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00b8fdd2-a364-4d6d-b773-de1407e7fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:20:05 INFO     Waiting for autoencoderV1@0.0.1 to be ready:\n",
      "2025-01-21 17:20:05 INFO     listening on https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=verify&id=740799ef-d515-4704-8718-903851c9899e$6mcNQQ8pV1oC-frgiwTZL&children=true\n",
      "2025-01-21 17:20:05 INFO     HTTP Request: GET https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=verify&id=740799ef-d515-4704-8718-903851c9899e$6mcNQQ8pV1oC-frgiwTZL&children=true \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 17:20:05 INFO     ack: Listening to events of jobs dependent on job 740799ef-d515-4704-8718-903851c9899e$6mcNQQ8pV1oC-frgiwTZL\n",
      "2025-01-21 17:20:05 INFO     autoencoderV1@0.0.1 build: active\n",
      "2025-01-21 17:20:06 INFO     autoencoderV1@0.0.1 build: completed\n",
      "{'data': {'returnvalue': {'digest': 'e73d693ccbed523f67e935efa41ae61b6969b3df3969ba75075c129ef69fd4ee', 'log': [], 'status': 'success'}}, 'job': {'id': '740799ef-d515-4704-8718-903851c9899e$IGqkit2bCuxsobW9x2iKQ', 'type': 'build'}, 'timestamp': '2025-01-21T16:20:06.702Z', 'function': {'name': 'autoencoderV1', 'version': '0.0.1', 'functionType': 'webscripts', 'runtime': 'web-python3', 'runtimeVersion': '0.2.0'}, '_links': {'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/build/740799ef-d515-4704-8718-903851c9899e$IGqkit2bCuxsobW9x2iKQ'}, 'webscript': {'href': 'https://api-aws-dev.waylay.io/registry/v2/webscripts/autoencoderV1/versions/0.0.1'}}}\n",
      "2025-01-21 17:20:06 INFO     autoencoderV1@0.0.1 deploy: waiting\n",
      "2025-01-21 17:20:06 INFO     autoencoderV1@0.0.1 deploy: active\n",
      "2025-01-21 17:20:06 INFO     autoencoderV1@0.0.1 deploy: completed\n",
      "{'data': {'returnvalue': {'deploySpec': {'service': 'web-459405a0456490a12ea734440535482292125551', 'image': 'registry.dev.waylay.io/openfaas-plugs/740799ef-d515-4704-8718-903851c9899e/cd428f6a235b5ab553064e93723a8aa9b979f557:0.0.1-8fac736e', 'namespace': 'openfaas-fn-740799ef-d515-4704-8718-903851c9899e', 'labels': {'networking/allow-internet-egress': 'true', 'com.openfaas.scale.zero': 'true', 'com.openfaas.scale.zero-duration': '12h', 'com.openfaas.scale.min': '1', 'com.openfaas.scale.max': '10', 'com.openfaas.scale.target': '20', 'com.openfaas.scale.target-proportion': '0.90', 'com.openfaas.scale.type': 'rps', 'io.waylay.runtime.name': 'web-python3', 'io.waylay.runtime.version': '0.2.0', 'io.waylay.tenant': '740799ef-d515-4704-8718-903851c9899e'}, 'annotations': {'io.waylay.registry.version': '2.18.1', 'io.waylay.function.name': 'autoencoderV1', 'io.waylay.function.version': '0.0.1', 'io.waylay.function.revision': '7329e57e571d100a34199e5524b5117a4c6aac8bf9e4a16e27ba751f7ab5ea96', 'com.openfaas.health.http.initialDelaySeconds': '0', 'com.openfaas.health.http.periodSeconds': '1', 'com.openfaas.health.http.successThreshold': '1', 'com.openfaas.health.http.failureThreshold': '10', 'com.openfaas.health.http.timeoutSeconds': '1', 'com.openfaas.profile': 'fn-nodepool-profile', 'com.openfaas.ready.http.path': '/_/ready', 'com.openfaas.ready.http.initialDelaySeconds': '0', 'com.openfaas.ready.http.periodSeconds': '1', 'com.openfaas.ready.http.successThreshold': '1', 'com.openfaas.ready.http.failureThreshold': '5', 'com.openfaas.ready.http.timeoutSeconds': '1', 'io.waylay.registry.health.http.path': '/_/ready'}, 'limits': {'memory': '2G', 'cpu': '150m'}, 'requests': {'memory': '1G', 'cpu': '25m'}}}}, 'job': {'id': '740799ef-d515-4704-8718-903851c9899e$y8Qxfc_eAH2BYdogYAe3H', 'type': 'deploy'}, 'timestamp': '2025-01-21T16:20:06.746Z', 'function': {'name': 'autoencoderV1', 'version': '0.0.1', 'functionType': 'webscripts', 'runtime': 'web-python3', 'runtimeVersion': '0.2.0'}, '_links': {'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/deploy/740799ef-d515-4704-8718-903851c9899e$y8Qxfc_eAH2BYdogYAe3H'}, 'webscript': {'href': 'https://api-aws-dev.waylay.io/registry/v2/webscripts/autoencoderV1/versions/0.0.1'}}}\n",
      "2025-01-21 17:20:06 INFO     autoencoderV1@0.0.1 verify: waiting\n",
      "2025-01-21 17:20:06 INFO     autoencoderV1@0.0.1 verify: active\n",
      "2025-01-21 17:20:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:20:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:21:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:21:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:22:08 INFO     close: Job with id 740799ef-d515-4704-8718-903851c9899e$6mcNQQ8pV1oC-frgiwTZL has completed\n",
      "2025-01-21 17:22:08 INFO     HTTP Request: GET https://api-aws-dev.waylay.io/registry/v2/webscripts/autoencoderV1/versions/0.0.1 \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 17:22:08 INFO     function autoencoderV1@0.0.1 has status running\n"
     ]
    }
   ],
   "source": [
    "# wait until the build, deploy and verify jobs for the webscript have finished\n",
    "# NOTE: this might take quite a few minutes, as the dependencies for torch webscripts are quite big and the images not yet optimised\n",
    "ref = await client.ml_tool.wait_until_ready(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30353da7-0331-4dee-b09a-7de2957894df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:22:09 INFO     HTTP Request: POST https://api-aws-dev.waylay.io/functions/v1/740799ef-d515-4704-8718-903851c9899e/autoencoderV1 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.3229316174983978,\n",
       " -0.36001601815223694,\n",
       " -0.39604517817497253,\n",
       " -0.32631659507751465,\n",
       " -0.3968595266342163,\n",
       " -0.4243429899215698,\n",
       " -0.4064428508281708,\n",
       " -0.3829203248023987,\n",
       " -0.41355741024017334,\n",
       " -0.27493223547935486,\n",
       " -0.3954361081123352,\n",
       " -0.3798944652080536,\n",
       " -0.3340390920639038,\n",
       " -0.3709794282913208,\n",
       " -0.37912046909332275,\n",
       " -0.3987690806388855,\n",
       " -0.31012246012687683,\n",
       " -0.40983518958091736,\n",
       " -0.4013403654098511,\n",
       " -0.3952208161354065]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the webscript invocation\n",
    "await client.ml_tool.test_webscript(ref, x_data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d5c730b-9929-49ad-bce9-242f174ebb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:22:09 INFO     HTTP Request: DELETE https://api-aws-dev.waylay.io/registry/v2/webscripts/autoencoderV1/versions/0.0.1?force=true \"HTTP/1.1 202 Accepted\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': \"Removing webscript version 'autoencoderV1@0.0.1'\",\n",
       " '_links': {'event': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=undeploy&id=740799ef-d515-4704-8718-903851c9899e$wjw76aPILglewoYdbq4KK&children=true'},\n",
       "  'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/undeploy/740799ef-d515-4704-8718-903851c9899e$wjw76aPILglewoYdbq4KK'}},\n",
       " 'versions': ['0.0.1']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the webscript\n",
    "await client.ml_tool.remove(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f95dcfc-fe9a-4370-9e96-443bc22e8ce9",
   "metadata": {},
   "source": [
    "## 4. Deploying as plug <a id=\"plug\"></a>\n",
    "Tell the adapter to configure itself as a plug: this generates a number of _assets_ that will be uploaded and define the plug behaviour\n",
    "* a `plug.json` _manifest_ file th`at defines the name, version, _runtime_, deploy settings, metadata ...\n",
    "* a `requirements.txt` package dependencies file\n",
    "* a `main.py` webscript script\n",
    "* additional scripts we added above, like the `autoencoder.py` and the `model-weights.pt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eba12a-193e-42e6-84ae-641fe71ae465",
   "metadata": {},
   "source": [
    "#### Initialize adapter for plug deployment (see how to create [adapter](#adapter))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3104e1c-d950-4f1f-b407-0b171bd5cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a local archive location\n",
    "PLUG_ARCHIVE_LOC = 'autoencoder-pytorch-plug'\n",
    "# make sure its empty\n",
    "!rm -fr autoencoder-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef413e89-743e-44ad-a01f-d93813dfeb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder.py <ml_adapter.base.assets.python.PythonScriptAsset>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ml_adapter.torch import V1TorchAdapter\n",
    "# create an ML adapter to wrap our model\n",
    "# by using a `weights.pt` postfix we are storing only the weights when serializing the model\n",
    "MODEL_PATH='model-weights.pt'\n",
    "adapter = V1TorchAdapter(model=model, model_path='model-weights.pt', location=ARCHIVE_LOC)\n",
    "\n",
    "# because we store only weights, the adapter archive needs to now about autoencode model class\n",
    "# Its not recommended to store full serialized models, as these are more brittle with respect versions of python and torch\n",
    "await adapter.add_script('autoencoder.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b504183-7e1a-4cf9-87f5-ce1615163264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[-0.3229316771030426,\n",
       "   -0.36001601815223694,\n",
       "   -0.3960452079772949,\n",
       "   -0.32631662487983704,\n",
       "   -0.3968595266342163,\n",
       "   -0.4243429899215698,\n",
       "   -0.40644288063049316,\n",
       "   -0.3829203248023987,\n",
       "   -0.41355741024017334,\n",
       "   -0.27493229508399963,\n",
       "   -0.3954361081123352,\n",
       "   -0.3798944652080536,\n",
       "   -0.3340391516685486,\n",
       "   -0.3709794878959656,\n",
       "   -0.37912052869796753,\n",
       "   -0.3987690806388855,\n",
       "   -0.3101225197315216,\n",
       "   -0.40983518958091736,\n",
       "   -0.40134039521217346,\n",
       "   -0.3952208459377289]]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the adapter exposes your model with a REST-compatible interface\n",
    "result = await adapter.call({\"instances\": [ x_data.tolist() ]}) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "097fdc6a-ae00-49ff-ad1d-49d1aeaf2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## configure any 'memory' or 'cpu' deploy settings \n",
    "deploy_overrides = {'limits' : { 'memory': '2G' }, 'requests' : { 'memory' : '1G' }}\n",
    "## configure the webscript to use our model\n",
    "adapter = adapter.as_plug({\n",
    "    'name': MODEL_NAME, \n",
    "    'description':'pytorch autoencoder for caats', \n",
    "    'deploy' : deploy_overrides                                                                                          \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4181dc8f-07e3-4c94-b8e4-97bae06dcbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-weights.pt',\n",
       " 'webscript.json',\n",
       " 'requirements.txt',\n",
       " 'main.py',\n",
       " 'autoencoder.py',\n",
       " 'plug.json']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await adapter.save()\n",
    "list(a.path for a in adapter.assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52918956-9691-4b24-946d-873bd8af5b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># ml_adapter.torch.adapter.V1TorchAdapter model adapter</span>\n",
       "<span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">os</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">ml_adapter.api.data</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">v1</span> <span class=\"k\">as</span> <span class=\"n\">V1</span>\n",
       "<span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">ml_adapter.torch.adapter</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">V1TorchAdapter</span>\n",
       "\n",
       "<span class=\"c1\"># optional type alias for plug response</span>\n",
       "<span class=\"n\">StatusAndRawData</span> <span class=\"o\">=</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">V1</span><span class=\"o\">.</span><span class=\"n\">V1PredictionResponse</span><span class=\"o\">|</span><span class=\"n\">V1</span><span class=\"o\">.</span><span class=\"n\">V1ErrorResponse</span><span class=\"p\">]</span>\n",
       "\n",
       "<span class=\"n\">STATE_OK</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;PREDICTED&#39;</span>\n",
       "<span class=\"n\">STATE_NOK</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;FAILED&#39;</span>\n",
       "\n",
       "<span class=\"n\">MODEL_PATH</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">&#39;MODEL_PATH&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;model-weights.pt&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">MODEL_CLASS</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">&#39;MODEL_CLASS&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;autoencoder.AutoEncoder&#39;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Initialize the model adapter.</span>\n",
       "<span class=\"c1\"># Provide a `model` argument if you want to create/load the model yourself.</span>\n",
       "<span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">V1TorchAdapter</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">model_path</span><span class=\"o\">=</span><span class=\"n\">MODEL_PATH</span><span class=\"p\">,</span> <span class=\"n\">model_class</span><span class=\"o\">=</span><span class=\"n\">MODEL_CLASS</span>\n",
       "<span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"k\">async</span> <span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">execute</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">:</span> <span class=\"n\">V1</span><span class=\"o\">.</span><span class=\"n\">V1Request</span><span class=\"p\">,</span> <span class=\"n\">console</span><span class=\"p\">,</span> <span class=\"n\">logger</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StatusAndRawData</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">try</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">call</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">STATE_OK</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">except</span> <span class=\"ne\">Exception</span> <span class=\"k\">as</span> <span class=\"n\">err</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">exception</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">error_message</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">console</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"n\">error_message</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">STATE_NOK</span><span class=\"p\">,</span> <span class=\"p\">{</span> <span class=\"s1\">&#39;error&#39;</span><span class=\"p\">:</span> <span class=\"n\">error_message</span><span class=\"p\">,</span> <span class=\"s1\">&#39;predictions&#39;</span><span class=\"p\">:</span> <span class=\"p\">[]</span> <span class=\"p\">})</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} ml\\PYZus{}adapter.torch.adapter.V1TorchAdapter model adapter}\n",
       "\\PY{k+kn}{import}\\PY{+w}{ }\\PY{n+nn}{os}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{ml\\PYZus{}adapter}\\PY{n+nn}{.}\\PY{n+nn}{api}\\PY{n+nn}{.}\\PY{n+nn}{data}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{v1} \\PY{k}{as} \\PY{n}{V1}\n",
       "\\PY{k+kn}{from}\\PY{+w}{ }\\PY{n+nn}{ml\\PYZus{}adapter}\\PY{n+nn}{.}\\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{adapter}\\PY{+w}{ }\\PY{k+kn}{import} \\PY{n}{V1TorchAdapter}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} optional type alias for plug response}\n",
       "\\PY{n}{StatusAndRawData} \\PY{o}{=} \\PY{n+nb}{tuple}\\PY{p}{[}\\PY{n+nb}{str}\\PY{p}{,} \\PY{n}{V1}\\PY{o}{.}\\PY{n}{V1PredictionResponse}\\PY{o}{|}\\PY{n}{V1}\\PY{o}{.}\\PY{n}{V1ErrorResponse}\\PY{p}{]}\n",
       "\n",
       "\\PY{n}{STATE\\PYZus{}OK} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PREDICTED}\\PY{l+s+s1}{\\PYZsq{}}\n",
       "\\PY{n}{STATE\\PYZus{}NOK} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{FAILED}\\PY{l+s+s1}{\\PYZsq{}}\n",
       "\n",
       "\\PY{n}{MODEL\\PYZus{}PATH} \\PY{o}{=} \\PY{n}{os}\\PY{o}{.}\\PY{n}{environ}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MODEL\\PYZus{}PATH}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZhy{}weights.pt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{n}{MODEL\\PYZus{}CLASS} \\PY{o}{=} \\PY{n}{os}\\PY{o}{.}\\PY{n}{environ}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MODEL\\PYZus{}CLASS}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{autoencoder.AutoEncoder}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Initialize the model adapter.}\n",
       "\\PY{c+c1}{\\PYZsh{} Provide a `model` argument if you want to create/load the model yourself.}\n",
       "\\PY{n}{adapter} \\PY{o}{=} \\PY{n}{V1TorchAdapter}\\PY{p}{(}\n",
       "    \\PY{n}{model\\PYZus{}path}\\PY{o}{=}\\PY{n}{MODEL\\PYZus{}PATH}\\PY{p}{,} \\PY{n}{model\\PYZus{}class}\\PY{o}{=}\\PY{n}{MODEL\\PYZus{}CLASS}\n",
       "\\PY{p}{)}\n",
       "\n",
       "\\PY{k}{async} \\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{execute}\\PY{p}{(}\\PY{n}{properties}\\PY{p}{:} \\PY{n}{V1}\\PY{o}{.}\\PY{n}{V1Request}\\PY{p}{,} \\PY{n}{console}\\PY{p}{,} \\PY{n}{logger}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{StatusAndRawData}\\PY{p}{:}\n",
       "    \\PY{k}{try}\\PY{p}{:}\n",
       "        \\PY{n}{result} \\PY{o}{=} \\PY{k}{await} \\PY{n}{adapter}\\PY{o}{.}\\PY{n}{call}\\PY{p}{(}\\PY{n}{properties}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{p}{(}\\PY{n}{STATE\\PYZus{}OK}\\PY{p}{,} \\PY{n}{result}\\PY{p}{)}\n",
       "    \\PY{k}{except} \\PY{n+ne}{Exception} \\PY{k}{as} \\PY{n}{err}\\PY{p}{:}\n",
       "        \\PY{n}{logger}\\PY{o}{.}\\PY{n}{exception}\\PY{p}{(}\\PY{n}{err}\\PY{p}{)}\n",
       "        \\PY{n}{error\\PYZus{}message} \\PY{o}{=} \\PY{n+nb}{str}\\PY{p}{(}\\PY{n}{err}\\PY{p}{)}\n",
       "        \\PY{n}{console}\\PY{o}{.}\\PY{n}{error}\\PY{p}{(}\\PY{n}{error\\PYZus{}message}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{p}{(}\\PY{n}{STATE\\PYZus{}NOK}\\PY{p}{,} \\PY{p}{\\PYZob{}} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{error}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{n}{error\\PYZus{}message}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{predictions}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{p}{[}\\PY{p}{]} \\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "# ml_adapter.torch.adapter.V1TorchAdapter model adapter\n",
       "import os\n",
       "from ml_adapter.api.data import v1 as V1\n",
       "from ml_adapter.torch.adapter import V1TorchAdapter\n",
       "\n",
       "# optional type alias for plug response\n",
       "StatusAndRawData = tuple[str, V1.V1PredictionResponse|V1.V1ErrorResponse]\n",
       "\n",
       "STATE_OK = 'PREDICTED'\n",
       "STATE_NOK = 'FAILED'\n",
       "\n",
       "MODEL_PATH = os.environ.get('MODEL_PATH', 'model-weights.pt')\n",
       "MODEL_CLASS = os.environ.get('MODEL_CLASS', 'autoencoder.AutoEncoder')\n",
       "\n",
       "# Initialize the model adapter.\n",
       "# Provide a `model` argument if you want to create/load the model yourself.\n",
       "adapter = V1TorchAdapter(\n",
       "    model_path=MODEL_PATH, model_class=MODEL_CLASS\n",
       ")\n",
       "\n",
       "async def execute(properties: V1.V1Request, console, logger) -> StatusAndRawData:\n",
       "    try:\n",
       "        result = await adapter.call(properties)\n",
       "        return (STATE_OK, result)\n",
       "    except Exception as err:\n",
       "        logger.exception(err)\n",
       "        error_message = str(err)\n",
       "        console.error(error_message)\n",
       "        return (STATE_NOK, { 'error': error_message, 'predictions': [] })"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets have a look at the generated python plug:\n",
    "display(Code(filename=f'{ARCHIVE_LOC}/main.py'))\n",
    "\n",
    "# You could adapt this script to have specific error handling or handling of request/response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d602439-bd03-4f37-a4d0-0c8f2b2d1e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-weights.pt',\n",
       " 'webscript.json',\n",
       " 'requirements.txt',\n",
       " 'main.py',\n",
       " 'autoencoder.py',\n",
       " 'plug.json']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.path for a in adapter.assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56979c72-5a25-4a23-ad00-14c1812cb2fd",
   "metadata": {},
   "source": [
    "### Uploading the plug using the SDK\n",
    "To upload these assets and create a plug, we need to call the [create plug](https://docs.waylay.io/openapi/public/redocly/registry.html#tag/Plugs/operation/create_plugs) REST api. \n",
    "\n",
    "The code belows uses the `ml_tool` plugin to handle this.\n",
    "Alternatively you could call `await adapter.save_archive()`\n",
    "which creates an `autoencoder-pytorch.tar.gz` archive that you can upload as a plug with `curl` or using the waylay console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7342717b-77f3-4fa0-8d29-99090b1b64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waylay.sdk import WaylayClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d86f1c86-d6e6-4d01-a43a-19533f35f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the SDK client\n",
    "client = WaylayClient.from_profile('staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d01f4031-2df2-4b80-a079-96785eadf62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:33:52 INFO     HTTP Request: DELETE https://api-aws-dev.waylay.io/registry/v2/plugs/autoencoderV1?force=true \"HTTP/1.1 202 Accepted\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ref = await client.registry.plugs.remove_versions(MODEL_NAME, query={'force': True})\n",
    "    await asyncio.sleep(5)\n",
    "except Exception as e:\n",
    "    print(f'nothing to delete? {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0010c395-aca0-4f10-80aa-ba64a6daf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:33:57 INFO     HTTP Request: POST https://api-aws-dev.waylay.io/registry/v2/plugs/?draft=false&comment=&async=true \"HTTP/1.1 202 Accepted\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': \"Building and deploying plug 'autoencoderV1@0.0.1'\",\n",
       " '_links': {'event': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=verify&id=740799ef-d515-4704-8718-903851c9899e$N9ySjGvV_jKsbvAgz7IwY&children=true'},\n",
       "  'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/verify/740799ef-d515-4704-8718-903851c9899e$N9ySjGvV_jKsbvAgz7IwY'}},\n",
       " 'entity': {'createdBy': 'users/08e92c94-0a45-4f69-8405-3c2e46dd0cf9',\n",
       "  'createdAt': '2025-01-21T16:33:57.825Z',\n",
       "  'updatedBy': 'users/08e92c94-0a45-4f69-8405-3c2e46dd0cf9',\n",
       "  'updatedAt': '2025-01-21T16:33:57.839Z',\n",
       "  'status': 'pending',\n",
       "  'runtime': {'deprecated': False,\n",
       "   'upgradable': False,\n",
       "   'name': 'plug-python3',\n",
       "   'version': '0.2.0'},\n",
       "  'deprecated': False,\n",
       "  'draft': False,\n",
       "  'plug': {'name': 'autoencoderV1',\n",
       "   'version': '0.0.1',\n",
       "   'runtime': 'plug-python3',\n",
       "   'metadata': {'tags': ['MLAdapter'],\n",
       "    'documentation': {'description': '',\n",
       "     'states': [{'name': 'PREDICTED',\n",
       "       'description': 'The model inference succeeded.'},\n",
       "      {'name': 'FAILED', 'description': 'The model inference failed.'}],\n",
       "     'input': [{'name': 'instances',\n",
       "       'description': 'A tensor of numeric input data (KServe V1 protocol)'}],\n",
       "     'output': [{'name': 'predictions',\n",
       "       'description': 'A tensor of numeric output data (KServe V1 protocol)'},\n",
       "      {'name': 'error',\n",
       "       'description': 'Failure reasion when FAILED. the predictions will be empty.'}]}},\n",
       "   'type': 'sensor',\n",
       "   'interface': {'states': ['PREDICTED', 'FAILED'],\n",
       "    'input': [{'name': 'instances', 'dataType': 'object', 'mandatory': True}],\n",
       "    'output': [{'name': 'predictions',\n",
       "      'dataType': 'object',\n",
       "      'mandatory': True},\n",
       "     {'name': 'error', 'dataType': 'string', 'mandatory': False}]},\n",
       "   'deploy': {'limits': {'memory': '2G'}, 'requests': {'memory': '1G'}},\n",
       "   'tags': ['MLAdapter']},\n",
       "  'updates': [{'operation': 'create',\n",
       "    'at': '2025-01-21T16:33:57.839Z',\n",
       "    'by': 'users/08e92c94-0a45-4f69-8405-3c2e46dd0cf9',\n",
       "    'comment': '',\n",
       "    'jobs': ['740799ef-d515-4704-8718-903851c9899e$N9ySjGvV_jKsbvAgz7IwY',\n",
       "     '740799ef-d515-4704-8718-903851c9899e$Zn-mFbuIcmg1Prp1vCC6n',\n",
       "     '740799ef-d515-4704-8718-903851c9899e$Ft78u0q4SlYA1DfUFmaxd']}]}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = await client.ml_tool.create_plug(adapter)\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82e7c0d0-d3ac-482c-b1c9-809d2f358db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:34:01 INFO     Waiting for autoencoderV1@0.0.1 to be ready:\n",
      "2025-01-21 17:34:01 INFO     listening on https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=verify&id=740799ef-d515-4704-8718-903851c9899e$N9ySjGvV_jKsbvAgz7IwY&children=true\n",
      "2025-01-21 17:34:01 INFO     HTTP Request: GET https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=verify&id=740799ef-d515-4704-8718-903851c9899e$N9ySjGvV_jKsbvAgz7IwY&children=true \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 17:34:01 INFO     ack: Listening to events of jobs dependent on job 740799ef-d515-4704-8718-903851c9899e$N9ySjGvV_jKsbvAgz7IwY\n",
      "2025-01-21 17:34:01 INFO     autoencoderV1@0.0.1 build: active\n",
      "2025-01-21 17:34:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:34:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:35:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:35:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:36:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:36:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:37:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:37:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:38:04 INFO     autoencoderV1@0.0.1 build: completed\n",
      "{'data': {'returnvalue': {'digest': '61a52e2562d1aae8d97fc4427af22a94c4fe703fd6de7e96a5338f30230cf429', 'log': [], 'status': 'success'}}, 'job': {'id': '740799ef-d515-4704-8718-903851c9899e$Ft78u0q4SlYA1DfUFmaxd', 'type': 'build'}, 'timestamp': '2025-01-21T16:38:04.813Z', 'function': {'name': 'autoencoderV1', 'version': '0.0.1', 'functionType': 'plugs', 'runtime': 'plug-python3', 'runtimeVersion': '0.2.0'}, '_links': {'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/build/740799ef-d515-4704-8718-903851c9899e$Ft78u0q4SlYA1DfUFmaxd'}, 'plug': {'href': 'https://api-aws-dev.waylay.io/registry/v2/plugs/autoencoderV1/versions/0.0.1'}}}\n",
      "2025-01-21 17:38:04 INFO     autoencoderV1@0.0.1 deploy: waiting\n",
      "2025-01-21 17:38:04 INFO     autoencoderV1@0.0.1 deploy: active\n",
      "2025-01-21 17:38:04 INFO     autoencoderV1@0.0.1 deploy: completed\n",
      "{'data': {'returnvalue': {'deploySpec': {'service': 'fn-459405a0456490a12ea734440535482292125551', 'image': 'registry.dev.waylay.io/openfaas-plugs/740799ef-d515-4704-8718-903851c9899e/201cefd24b2e6e7caa7db49c849e5e655cdaeb9e:0.0.1-c4e063b9', 'namespace': 'openfaas-fn-740799ef-d515-4704-8718-903851c9899e', 'labels': {'networking/allow-internet-egress': 'true', 'com.openfaas.scale.zero': 'true', 'com.openfaas.scale.zero-duration': '12h', 'com.openfaas.scale.min': '1', 'com.openfaas.scale.max': '10', 'com.openfaas.scale.target': '20', 'com.openfaas.scale.target-proportion': '0.90', 'com.openfaas.scale.type': 'rps', 'io.waylay.runtime.name': 'plug-python3', 'io.waylay.runtime.version': '0.2.0', 'io.waylay.tenant': '740799ef-d515-4704-8718-903851c9899e', 'io.waylay.plugs.type': 'sensor'}, 'annotations': {'io.waylay.registry.version': '2.18.1', 'io.waylay.function.name': 'autoencoderV1', 'io.waylay.function.version': '0.0.1', 'io.waylay.function.revision': 'b89c0c344c5ae6b8d9d3f2a484b7aff712e5f23cf6aa8aba9d488f5b0ba2ee77', 'com.openfaas.health.http.initialDelaySeconds': '0', 'com.openfaas.health.http.periodSeconds': '1', 'com.openfaas.health.http.successThreshold': '1', 'com.openfaas.health.http.failureThreshold': '10', 'com.openfaas.health.http.timeoutSeconds': '1', 'com.openfaas.profile': 'fn-nodepool-profile', 'com.openfaas.ready.http.path': '/_/ready', 'com.openfaas.ready.http.initialDelaySeconds': '0', 'com.openfaas.ready.http.periodSeconds': '1', 'com.openfaas.ready.http.successThreshold': '1', 'com.openfaas.ready.http.failureThreshold': '5', 'com.openfaas.ready.http.timeoutSeconds': '1', 'io.waylay.registry.health.http.path': '/_/ready'}, 'limits': {'memory': '2G', 'cpu': '600m'}, 'requests': {'memory': '1G', 'cpu': '25m'}}}}, 'job': {'id': '740799ef-d515-4704-8718-903851c9899e$Zn-mFbuIcmg1Prp1vCC6n', 'type': 'deploy'}, 'timestamp': '2025-01-21T16:38:04.858Z', 'function': {'name': 'autoencoderV1', 'version': '0.0.1', 'functionType': 'plugs', 'runtime': 'plug-python3', 'runtimeVersion': '0.2.0'}, '_links': {'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/deploy/740799ef-d515-4704-8718-903851c9899e$Zn-mFbuIcmg1Prp1vCC6n'}, 'plug': {'href': 'https://api-aws-dev.waylay.io/registry/v2/plugs/autoencoderV1/versions/0.0.1'}}}\n",
      "2025-01-21 17:38:04 INFO     autoencoderV1@0.0.1 verify: waiting\n",
      "2025-01-21 17:38:04 INFO     autoencoderV1@0.0.1 verify: active\n",
      "2025-01-21 17:38:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:38:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:39:17 INFO     keep-alive: {}\n",
      "2025-01-21 17:39:47 INFO     keep-alive: {}\n",
      "2025-01-21 17:39:52 INFO     close: Job with id 740799ef-d515-4704-8718-903851c9899e$N9ySjGvV_jKsbvAgz7IwY has completed\n",
      "2025-01-21 17:39:53 INFO     HTTP Request: GET https://api-aws-dev.waylay.io/registry/v2/plugs/autoencoderV1/versions/0.0.1 \"HTTP/1.1 200 OK\"\n",
      "2025-01-21 17:39:53 INFO     function autoencoderV1@0.0.1 has status running\n"
     ]
    }
   ],
   "source": [
    "# wait until the build, deploy and verify jobs for the webscript have finished\n",
    "# NOTE: this might take quite a few minutes, as the dependencies for torch webscripts are quite big and the images not yet optimised\n",
    "ref = await client.ml_tool.wait_until_ready(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94e7328f-79db-4b4c-8e61-cb332a1adac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:39:53 INFO     HTTP Request: POST https://api-aws-dev.waylay.io/rules/v1/sensors/autoencoderV1/versions/0.0.1 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.3229316174983978,\n",
       " -0.36001601815223694,\n",
       " -0.39604517817497253,\n",
       " -0.32631659507751465,\n",
       " -0.3968595266342163,\n",
       " -0.4243429899215698,\n",
       " -0.4064428508281708,\n",
       " -0.3829203248023987,\n",
       " -0.41355741024017334,\n",
       " -0.27493223547935486,\n",
       " -0.3954361081123352,\n",
       " -0.3798944652080536,\n",
       " -0.3340390920639038,\n",
       " -0.3709794282913208,\n",
       " -0.37912046909332275,\n",
       " -0.3987690806388855,\n",
       " -0.31012246012687683,\n",
       " -0.40983518958091736,\n",
       " -0.4013403654098511,\n",
       " -0.3952208161354065]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the plug invocation\n",
    "await client.ml_tool.test_plug(ref, x_data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0a03afe-e35c-441d-bdb1-f56c13a33622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 17:39:53 INFO     HTTP Request: DELETE https://api-aws-dev.waylay.io/registry/v2/plugs/autoencoderV1/versions/0.0.1?force=true \"HTTP/1.1 202 Accepted\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': \"Removing plug version 'autoencoderV1@0.0.1'\",\n",
       " '_links': {'event': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=undeploy&id=740799ef-d515-4704-8718-903851c9899e$h3vUl0PHqtrvk8N-2zc0N&children=true'},\n",
       "  'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/undeploy/740799ef-d515-4704-8718-903851c9899e$h3vUl0PHqtrvk8N-2zc0N'}},\n",
       " 'versions': ['0.0.1']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the plug\n",
    "await client.ml_tool.remove(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc1aca-9fc6-4ae3-926c-8a8d0f67aa08",
   "metadata": {},
   "source": [
    "#### About `ml_tool`\n",
    "The `client.ml_tool` methods are essentialy wrappers around the methods of the [registry](https://docs.waylay.io/openapi/public/redocly/registry.html#tag/Webscripts) service. Alternatively you can use the [`client.registry.webscript`](https://github.com/waylayio/waylay-sdk-registry-py) methods directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c04d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad85121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e0d7de2-4fcd-49cc-908d-343599dcb241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions used:\n",
      "- waylay-ml-adapter-sdk: 0.0.9\n",
      "- waylay-ml-adapter-torch: 0.0.9\n",
      "- torch: 2.5.1\n",
      "- waylay-sdk-core: 0.3.2\n",
      "- waylay-sdk-registry: 2.17.1.20241025\n",
      "- waylay-sdk-rules: 6.12.0.20241025\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "print('versions used:')\n",
    "for lib in ['waylay-ml-adapter-sdk','waylay-ml-adapter-torch','torch','waylay-sdk-core','waylay-sdk-registry','waylay-sdk-rules']:\n",
    "    print(f'- {lib}: {importlib.metadata.version(lib)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
