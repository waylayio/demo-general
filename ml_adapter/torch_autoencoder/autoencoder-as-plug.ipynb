{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46523964-f381-46ff-b009-76b32cdc3b00",
   "metadata": {},
   "source": [
    "# A pytorch ML adapter demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd854b-9a6e-4bac-9650-5d86b3ea56d5",
   "metadata": {},
   "source": [
    "#### Preamble\n",
    "Demo of a relatively small pytorch model.\n",
    "This notebook uses the [ml_adapter_torch](../../env/ml_adapter_torch) dependencies.\n",
    "To start: \n",
    "```\n",
    "bin/jupyter_notebook env/ml_adapter_torch ml_adapter/torch_autoencoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53829b8-6fde-490f-a870-c5f540f3e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.9\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d623cc-fad6-4d2c-9e43-8bb9ccde3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sdk profile used to connect\n",
    "PROFILE='_default_'\n",
    "LOG_LEVEL='INFO'\n",
    "MODEL_NAME='autoencoderV1'\n",
    "MODEL_VERSION='1.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfbefcf-84f8-40d2-9393-ed3988630147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup INFO logging to see http requests made.\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=LOG_LEVEL,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e989be6-88be-40c9-b80a-e77d5f152eb8",
   "metadata": {},
   "source": [
    "## Pytorch example\n",
    "\n",
    "A simple auto-encoder pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fbe4087-26be-4945-8f1a-96fab99d3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b779cd6-2c39-4efa-95ef-6a8389ec7820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">torch</span>\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">AutoEncoder</span><span class=\"p\">(</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Module</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"nb\">super</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"fm\">__init__</span><span class=\"p\">()</span>\n",
       "<span class=\"w\">        </span><span class=\"sd\">&quot;&quot;&quot;</span>\n",
       "<span class=\"sd\">        Create a simple AutoEncoder</span>\n",
       "<span class=\"sd\">        &quot;&quot;&quot;</span>\n",
       "        <span class=\"c1\"># Use an AutoEncoder and try to reconstruct both signals (the 20 samples back)</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">),</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Sequential</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">5</span><span class=\"p\">,</span> <span class=\"mi\">10</span><span class=\"p\">),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">ReLU</span><span class=\"p\">(),</span>\n",
       "            <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">Linear</span><span class=\"p\">(</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"mi\">20</span><span class=\"p\">),</span>\n",
       "        <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">x</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">encoded</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encoder</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">decoded</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">decoder</span><span class=\"p\">(</span><span class=\"n\">encoded</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">decoded</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{torch}\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{AutoEncoder}\\PY{p}{(}\\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Module}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb}{super}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n+nf+fm}{\\PYZus{}\\PYZus{}init\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{p}{)}\n",
       "\\PY{+w}{        }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\\PY{l+s+sd}{        Create a simple AutoEncoder}\n",
       "\\PY{l+s+sd}{        \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "        \\PY{c+c1}{\\PYZsh{} Use an AutoEncoder and try to reconstruct both signals (the 20 samples back)}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{20}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{ReLU}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{5}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder} \\PY{o}{=} \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Sequential}\\PY{p}{(}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{5}\\PY{p}{,} \\PY{l+m+mi}{10}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{ReLU}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "            \\PY{n}{torch}\\PY{o}{.}\\PY{n}{nn}\\PY{o}{.}\\PY{n}{Linear}\\PY{p}{(}\\PY{l+m+mi}{10}\\PY{p}{,} \\PY{l+m+mi}{20}\\PY{p}{)}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{forward}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{x}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{encoded} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{encoder}\\PY{p}{(}\\PY{n}{x}\\PY{p}{)}\n",
       "        \\PY{n}{decoded} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{decoder}\\PY{p}{(}\\PY{n}{encoded}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{n}{decoded}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import torch\n",
       "\n",
       "class AutoEncoder(torch.nn.Module):\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        \"\"\"\n",
       "        Create a simple AutoEncoder\n",
       "        \"\"\"\n",
       "        # Use an AutoEncoder and try to reconstruct both signals (the 20 samples back)\n",
       "        self.encoder = torch.nn.Sequential(\n",
       "            torch.nn.Linear(20, 10),\n",
       "            torch.nn.ReLU(),\n",
       "            torch.nn.Linear(10, 5),\n",
       "        )\n",
       "\n",
       "        self.decoder = torch.nn.Sequential(\n",
       "            torch.nn.Linear(5, 10),\n",
       "            torch.nn.ReLU(),\n",
       "            torch.nn.Linear(10, 20),\n",
       "        )\n",
       "\n",
       "    def forward(self, x):\n",
       "        encoded = self.encoder(x)\n",
       "        decoded = self.decoder(encoded)\n",
       "        return decoded"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we saved our model class in a `autoencoder.py` file\n",
    "from IPython.display import Code, Markdown\n",
    "display(Code(filename='autoencoder.py'))\n",
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5409ee2-ffb0-450b-91a6-9be5b857c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some pretrained weights\n",
    "weights_path = 'AutoEncoderWeights.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a7a6e6-ece7-49d3-8bba-a128ebc621c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = AutoEncoder()\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f74982-aea0-4d08-8ef7-71c7fec68a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6440,  0.7529,  1.1046,  1.1565,  0.5734,  0.0943, -0.0062, -0.3886,\n",
       "         0.1544,  0.2429,  1.3781, -1.0619,  1.0171, -0.8512, -0.3010, -0.4041,\n",
       "         0.7137, -0.4662,  0.1278,  1.2790])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = torch.randn(20, dtype=torch.float32)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cef5213-7a07-4360-80b1-6bd352a188a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2374, 0.2425, 0.2575, 0.2413, 0.2440, 0.2275, 0.2310, 0.2287, 0.2211,\n",
       "        0.2760, 0.2447, 0.2860, 0.2459, 0.2123, 0.2231, 0.2105, 0.2465, 0.1848,\n",
       "        0.2116, 0.2709], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(x_data)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc56c20c-e56c-476b-ba70-27e40a479b1f",
   "metadata": {},
   "source": [
    "## The adapter\n",
    "The `V1TorchAdapter` from the `ml_adapter.torch` module wraps our model in a script that can be used as a waylay webscript or plug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7023e2eb-4ebb-4f5e-a436-5e11b07222e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a local archive location\n",
    "ARCHIVE_LOC = 'autoencoder-pytorch'\n",
    "# make sure its empty\n",
    "!rm -fr autoencoder-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc2c179-9eb8-4406-ba6a-ef38f6786336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_adapter.torch import V1TorchAdapter\n",
    "# create an ML adapter to wrap our model\n",
    "# by using a `weights.pt` postfix we are storing only the weights when serializing the model\n",
    "MODEL_PATH='model-weights.pt'\n",
    "adapter = V1TorchAdapter(model=model, model_path='model-weights.pt', location=ARCHIVE_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47bc96ed-9f3c-4958-a718-4eb7b18735d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.23736661672592163,\n",
       "   0.24252289533615112,\n",
       "   0.2575299143791199,\n",
       "   0.24128106236457825,\n",
       "   0.24399690330028534,\n",
       "   0.22746336460113525,\n",
       "   0.2309776097536087,\n",
       "   0.2286645472049713,\n",
       "   0.22113662958145142,\n",
       "   0.27599504590034485,\n",
       "   0.24474786221981049,\n",
       "   0.28604230284690857,\n",
       "   0.24586451053619385,\n",
       "   0.21225886046886444,\n",
       "   0.223057359457016,\n",
       "   0.21050433814525604,\n",
       "   0.2464890033006668,\n",
       "   0.18476180732250214,\n",
       "   0.21161124110221863,\n",
       "   0.27093297243118286]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the adapter exposes your model with a REST-compatible interface\n",
    "result = await adapter.call({\"instances\": [ x_data.tolist() ]}) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7c77d97-61a2-488c-8e07-8c894b7a8f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder.py <ml_adapter.base.assets.python.PythonScriptAsset>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because we store only weights, the adapter archive needs to now about autoencode model class:\n",
    "await adapter.add_script('autoencoder.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9872aa-6cab-43ea-9fd4-87f1a43390fc",
   "metadata": {},
   "source": [
    "### Creating the plug\n",
    "Tell the adapter to configure itself as a plug: this generates a number of _assets_ that will be uploaded and define the plug behaviour\n",
    "* a `plug.json` _manifest_ file that defines the name, version, _runtime_, deploy settings, metadata ...\n",
    "* a `requirements.txt` package dependencies file\n",
    "* a `main.py` webscript script\n",
    "* additional scripts we added above, like the `autoencoder.py` and the `model-weights.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f68556cd-921d-495d-93d1-a94c7897d1e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Multiple assets of type <class 'ml_adapter.base.assets.manifest.FunctionManifestAsset'> found: [webscript.json <ml_adapter.base.assets.manifest.WebscriptManifestAsset>, plug.json <ml_adapter.base.assets.manifest.PlugManifestAsset>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m deploy_overrides \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlimits\u001b[39m\u001b[38;5;124m'\u001b[39m : { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2G\u001b[39m\u001b[38;5;124m'\u001b[39m }, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequests\u001b[39m\u001b[38;5;124m'\u001b[39m : { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1G\u001b[39m\u001b[38;5;124m'\u001b[39m }}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## configure the webscript to use our model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m adapter \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39mas_plug({\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: MODEL_NAME, \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch autoencoder for caats\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeploy\u001b[39m\u001b[38;5;124m'\u001b[39m : deploy_overrides                                                                                          \n\u001b[1;32m      8\u001b[0m })\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_torch_demo/lib/python3.11/site-packages/ml_adapter/base/assets/manifest.py:200\u001b[0m, in \u001b[0;36mWithManifest.as_plug\u001b[0;34m(self, manifest, **_kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_plug\u001b[39m(\u001b[38;5;28mself\u001b[39m, manifest: ManifestSpec, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Make sure that a plug manifest is present.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_function(manifest, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplug\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_torch_demo/lib/python3.11/site-packages/ml_adapter/base/assets/manifest.py:167\u001b[0m, in \u001b[0;36mWithManifest._as_function\u001b[0;34m(self, manifest, function_type)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, manifest: ManifestSpec, function_type: FunctionType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# switch function type if neccessary\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     manifest_asset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assure_manifest_type(\n\u001b[1;32m    168\u001b[0m         WebscriptManifestAsset\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m function_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwebscript\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m PlugManifestAsset\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    172\u001b[0m     manifest_asset\u001b[38;5;241m.\u001b[39mmerge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_manifest(function_type))\n\u001b[1;32m    173\u001b[0m     manifest_asset\u001b[38;5;241m.\u001b[39mmerge(manifest)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_torch_demo/lib/python3.11/site-packages/ml_adapter/base/assets/manifest.py:157\u001b[0m, in \u001b[0;36mWithManifest._assure_manifest_type\u001b[0;34m(self, manifest_type)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assure_manifest_type\u001b[39m(\u001b[38;5;28mself\u001b[39m, manifest_type: \u001b[38;5;28mtype\u001b[39m[FunctionManifestAsset]):\n\u001b[0;32m--> 157\u001b[0m     manifest_asset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massets\u001b[38;5;241m.\u001b[39mget(asset_type\u001b[38;5;241m=\u001b[39mFunctionManifestAsset)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manifest_asset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(manifest_asset, manifest_type):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massets\u001b[38;5;241m.\u001b[39mchildren\u001b[38;5;241m.\u001b[39mremove(manifest_asset)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/my_torch_demo/lib/python3.11/site-packages/ml_adapter/base/assets/base.py:586\u001b[0m, in \u001b[0;36mAssetsFolder.get\u001b[0;34m(self, asset_type, path_includes, path_excludes, recursive, **kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m asset_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(asset_it, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asset_2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple assets of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masset_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[asset,\u001b[38;5;250m \u001b[39masset_2]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m     )\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m asset\n",
      "\u001b[0;31mIndexError\u001b[0m: Multiple assets of type <class 'ml_adapter.base.assets.manifest.FunctionManifestAsset'> found: [webscript.json <ml_adapter.base.assets.manifest.WebscriptManifestAsset>, plug.json <ml_adapter.base.assets.manifest.PlugManifestAsset>]"
     ]
    }
   ],
   "source": [
    "## configure any 'memory' or 'cpu' deploy settings \n",
    "deploy_overrides = {'limits' : { 'memory': '2G' }, 'requests' : { 'memory' : '1G' }}\n",
    "## configure the webscript to use our model\n",
    "adapter = adapter.as_plug({\n",
    "    'name': MODEL_NAME, \n",
    "    'description':'pytorch autoencoder for caats', \n",
    "    'deploy' : deploy_overrides                                                                                          \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63199dc8-edb2-46f9-8ef3-4f398fa59d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adapter.assets.children[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81b6e0c4-413a-4d40-a37d-390cd2c071df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[openapi.json <ml_adapter.base.assets.openapi.OpenApiAsset>,\n",
       " requirements.txt <ml_adapter.base.assets.python.PythonRequirementsAsset>,\n",
       " main.py <ml_adapter.base.assets.python.PythonScriptAsset>,\n",
       " lib <ml_adapter.base.assets.python.PythonLibAssetDir>,\n",
       " model-weights.pt <ml_adapter.torch.adapter.TorchModelWeightsAsset>,\n",
       " plug.json <ml_adapter.base.assets.manifest.PlugManifestAsset>,\n",
       " autoencoder.py <ml_adapter.base.assets.python.PythonScriptAsset>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter.assets.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e75891d-87fc-4b58-925f-e779595a3b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openapi.json',\n",
       " 'requirements.txt',\n",
       " 'main.py',\n",
       " 'model-weights.pt',\n",
       " 'autoencoder.py',\n",
       " 'plug.json']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await adapter.save()\n",
    "list(a.path for a in adapter.assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c2ce077-f293-4c2f-9c6f-7784ddb3fdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\"># ml_adapter.torch.adapter.V1TorchAdapter model adapter</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">ml_adapter.api.data</span> <span class=\"kn\">import</span> <span class=\"n\">v1</span> <span class=\"k\">as</span> <span class=\"n\">V1</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">ml_adapter.torch.adapter</span> <span class=\"kn\">import</span> <span class=\"n\">V1TorchAdapter</span>\n",
       "\n",
       "<span class=\"c1\"># optional type alias for plug response</span>\n",
       "<span class=\"n\">StatusAndRawData</span> <span class=\"o\">=</span> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">,</span> <span class=\"n\">V1</span><span class=\"o\">.</span><span class=\"n\">V1PredictionResponse</span><span class=\"o\">|</span><span class=\"n\">V1</span><span class=\"o\">.</span><span class=\"n\">V1ErrorResponse</span><span class=\"p\">]</span>\n",
       "\n",
       "<span class=\"n\">STATE_OK</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;PREDICTED&#39;</span>\n",
       "<span class=\"n\">STATE_NOK</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;FAILED&#39;</span>\n",
       "\n",
       "<span class=\"n\">MODEL_PATH</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">&#39;MODEL_PATH&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;model-weights.pt&#39;</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">MODEL_CLASS</span> <span class=\"o\">=</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s1\">&#39;MODEL_CLASS&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;autoencoder.AutoEncoder&#39;</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># Initialize the model adapter.</span>\n",
       "<span class=\"c1\"># Provide a `model` argument if you want to create/load the model yourself.</span>\n",
       "<span class=\"n\">adapter</span> <span class=\"o\">=</span> <span class=\"n\">V1TorchAdapter</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">model_path</span><span class=\"o\">=</span><span class=\"n\">MODEL_PATH</span><span class=\"p\">,</span> <span class=\"n\">model_class</span><span class=\"o\">=</span><span class=\"n\">MODEL_CLASS</span>\n",
       "<span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"k\">async</span> <span class=\"k\">def</span> <span class=\"nf\">execute</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">:</span> <span class=\"n\">V1</span><span class=\"o\">.</span><span class=\"n\">V1Request</span><span class=\"p\">,</span> <span class=\"n\">console</span><span class=\"p\">,</span> <span class=\"n\">logger</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">StatusAndRawData</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">try</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">result</span> <span class=\"o\">=</span> <span class=\"k\">await</span> <span class=\"n\">adapter</span><span class=\"o\">.</span><span class=\"n\">call</span><span class=\"p\">(</span><span class=\"n\">properties</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">STATE_OK</span><span class=\"p\">,</span> <span class=\"n\">result</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">except</span> <span class=\"ne\">Exception</span> <span class=\"k\">as</span> <span class=\"n\">err</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">logger</span><span class=\"o\">.</span><span class=\"n\">exception</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">error_message</span> <span class=\"o\">=</span> <span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">err</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">console</span><span class=\"o\">.</span><span class=\"n\">error</span><span class=\"p\">(</span><span class=\"n\">error_message</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">STATE_NOK</span><span class=\"p\">,</span> <span class=\"p\">{</span> <span class=\"s1\">&#39;error&#39;</span><span class=\"p\">:</span> <span class=\"n\">error_message</span><span class=\"p\">,</span> <span class=\"s1\">&#39;predictions&#39;</span><span class=\"p\">:</span> <span class=\"p\">[]</span> <span class=\"p\">})</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{c+c1}{\\PYZsh{} ml\\PYZus{}adapter.torch.adapter.V1TorchAdapter model adapter}\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{os}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{ml\\PYZus{}adapter}\\PY{n+nn}{.}\\PY{n+nn}{api}\\PY{n+nn}{.}\\PY{n+nn}{data} \\PY{k+kn}{import} \\PY{n}{v1} \\PY{k}{as} \\PY{n}{V1}\n",
       "\\PY{k+kn}{from} \\PY{n+nn}{ml\\PYZus{}adapter}\\PY{n+nn}{.}\\PY{n+nn}{torch}\\PY{n+nn}{.}\\PY{n+nn}{adapter} \\PY{k+kn}{import} \\PY{n}{V1TorchAdapter}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} optional type alias for plug response}\n",
       "\\PY{n}{StatusAndRawData} \\PY{o}{=} \\PY{n+nb}{tuple}\\PY{p}{[}\\PY{n+nb}{str}\\PY{p}{,} \\PY{n}{V1}\\PY{o}{.}\\PY{n}{V1PredictionResponse}\\PY{o}{|}\\PY{n}{V1}\\PY{o}{.}\\PY{n}{V1ErrorResponse}\\PY{p}{]}\n",
       "\n",
       "\\PY{n}{STATE\\PYZus{}OK} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{PREDICTED}\\PY{l+s+s1}{\\PYZsq{}}\n",
       "\\PY{n}{STATE\\PYZus{}NOK} \\PY{o}{=} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{FAILED}\\PY{l+s+s1}{\\PYZsq{}}\n",
       "\n",
       "\\PY{n}{MODEL\\PYZus{}PATH} \\PY{o}{=} \\PY{n}{os}\\PY{o}{.}\\PY{n}{environ}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MODEL\\PYZus{}PATH}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{model\\PYZhy{}weights.pt}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\\PY{n}{MODEL\\PYZus{}CLASS} \\PY{o}{=} \\PY{n}{os}\\PY{o}{.}\\PY{n}{environ}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{MODEL\\PYZus{}CLASS}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{autoencoder.AutoEncoder}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{)}\n",
       "\n",
       "\\PY{c+c1}{\\PYZsh{} Initialize the model adapter.}\n",
       "\\PY{c+c1}{\\PYZsh{} Provide a `model` argument if you want to create/load the model yourself.}\n",
       "\\PY{n}{adapter} \\PY{o}{=} \\PY{n}{V1TorchAdapter}\\PY{p}{(}\n",
       "    \\PY{n}{model\\PYZus{}path}\\PY{o}{=}\\PY{n}{MODEL\\PYZus{}PATH}\\PY{p}{,} \\PY{n}{model\\PYZus{}class}\\PY{o}{=}\\PY{n}{MODEL\\PYZus{}CLASS}\n",
       "\\PY{p}{)}\n",
       "\n",
       "\\PY{k}{async} \\PY{k}{def} \\PY{n+nf}{execute}\\PY{p}{(}\\PY{n}{properties}\\PY{p}{:} \\PY{n}{V1}\\PY{o}{.}\\PY{n}{V1Request}\\PY{p}{,} \\PY{n}{console}\\PY{p}{,} \\PY{n}{logger}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{StatusAndRawData}\\PY{p}{:}\n",
       "    \\PY{k}{try}\\PY{p}{:}\n",
       "        \\PY{n}{result} \\PY{o}{=} \\PY{k}{await} \\PY{n}{adapter}\\PY{o}{.}\\PY{n}{call}\\PY{p}{(}\\PY{n}{properties}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{p}{(}\\PY{n}{STATE\\PYZus{}OK}\\PY{p}{,} \\PY{n}{result}\\PY{p}{)}\n",
       "    \\PY{k}{except} \\PY{n+ne}{Exception} \\PY{k}{as} \\PY{n}{err}\\PY{p}{:}\n",
       "        \\PY{n}{logger}\\PY{o}{.}\\PY{n}{exception}\\PY{p}{(}\\PY{n}{err}\\PY{p}{)}\n",
       "        \\PY{n}{error\\PYZus{}message} \\PY{o}{=} \\PY{n+nb}{str}\\PY{p}{(}\\PY{n}{err}\\PY{p}{)}\n",
       "        \\PY{n}{console}\\PY{o}{.}\\PY{n}{error}\\PY{p}{(}\\PY{n}{error\\PYZus{}message}\\PY{p}{)}\n",
       "        \\PY{k}{return} \\PY{p}{(}\\PY{n}{STATE\\PYZus{}NOK}\\PY{p}{,} \\PY{p}{\\PYZob{}} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{error}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{n}{error\\PYZus{}message}\\PY{p}{,} \\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{predictions}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{:} \\PY{p}{[}\\PY{p}{]} \\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "\n",
       "# ml_adapter.torch.adapter.V1TorchAdapter model adapter\n",
       "import os\n",
       "from ml_adapter.api.data import v1 as V1\n",
       "from ml_adapter.torch.adapter import V1TorchAdapter\n",
       "\n",
       "# optional type alias for plug response\n",
       "StatusAndRawData = tuple[str, V1.V1PredictionResponse|V1.V1ErrorResponse]\n",
       "\n",
       "STATE_OK = 'PREDICTED'\n",
       "STATE_NOK = 'FAILED'\n",
       "\n",
       "MODEL_PATH = os.environ.get('MODEL_PATH', 'model-weights.pt')\n",
       "MODEL_CLASS = os.environ.get('MODEL_CLASS', 'autoencoder.AutoEncoder')\n",
       "\n",
       "# Initialize the model adapter.\n",
       "# Provide a `model` argument if you want to create/load the model yourself.\n",
       "adapter = V1TorchAdapter(\n",
       "    model_path=MODEL_PATH, model_class=MODEL_CLASS\n",
       ")\n",
       "\n",
       "async def execute(properties: V1.V1Request, console, logger) -> StatusAndRawData:\n",
       "    try:\n",
       "        result = await adapter.call(properties)\n",
       "        return (STATE_OK, result)\n",
       "    except Exception as err:\n",
       "        logger.exception(err)\n",
       "        error_message = str(err)\n",
       "        console.error(error_message)\n",
       "        return (STATE_NOK, { 'error': error_message, 'predictions': [] })"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets have a look at the generated python plug:\n",
    "display(Code(filename=f'{ARCHIVE_LOC}/main.py'))\n",
    "\n",
    "# You could adapt this script to have specific error handling or handling of request/response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d65e204-c421-4026-a337-330dcbeca22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once stored, the adapter can be restored later with\n",
    "# adapter = await V1TorchAdapter(model_path='model-weights.pt', model_class=AutoEncoder, location=ARCHIVE_LOC).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9d9e482-cf73-4631-b94a-a732b158701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[openapi.json <ml_adapter.base.assets.openapi.OpenApiAsset>,\n",
       " requirements.txt <ml_adapter.base.assets.python.PythonRequirementsAsset>,\n",
       " main.py <ml_adapter.base.assets.python.PythonScriptAsset>,\n",
       " model-weights.pt <ml_adapter.torch.adapter.TorchModelWeightsAsset>,\n",
       " plug.json <ml_adapter.base.assets.manifest.PlugManifestAsset>,\n",
       " autoencoder.py <ml_adapter.base.assets.python.PythonScriptAsset>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(adapter.assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef9453f4-3352-4eeb-a79c-4b3656a70624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openapi.json',\n",
       " 'requirements.txt',\n",
       " 'main.py',\n",
       " 'model-weights.pt',\n",
       " 'plug.json',\n",
       " 'autoencoder.py']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.path for a in adapter.assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e0183-cf8c-4225-965e-89b75b3c781d",
   "metadata": {},
   "source": [
    "### Uploading the plug using the SDK\n",
    "To upload these assets and create a plug, we need to call the [create plug](https://docs.waylay.io/openapi/public/redocly/registry.html#tag/Plugs/operation/create_plugs) REST api. \n",
    "\n",
    "The code belows uses the `ml_tool` plugin to handle this.\n",
    "Alternatively you could call `await adapter.save_archive()`\n",
    "which creates an `autoencoder-pytorch.tar.gz` archive that you can upload as a plug with `curl` or using the waylay console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbb7b49c-cc60-4e8a-afae-a2908a6caf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waylay.sdk import WaylayClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecca79ac-ad09-43c4-876a-7a5e9fd7b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the SDK client\n",
    "client = WaylayClient.from_profile('staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70434f0b-6bdc-4ca8-8214-0dd40ba5bfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 14:53:22 INFO     HTTP Request: POST https://api-aws-dev.waylay.io/accounts/v1/tokens?grant_type=client_credentials \"HTTP/1.1 200 OK\"\n",
      "2024-06-11 14:53:23 INFO     HTTP Request: POST https://api-aws-dev.waylay.io/registry/v2/plugs/?draft=false&comment=&async=true \"HTTP/1.1 202 Accepted\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'Building and deploying plug autoencoderV1@0.0.1',\n",
       " '_links': {'event': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/events?type=verify&id=740799ef-d515-4704-8718-903851c9899e$SxMJXAcOF0Aqs9UljAFR8&children=true'},\n",
       "  'job': {'href': 'https://api-aws-dev.waylay.io/registry/v2/jobs/verify/740799ef-d515-4704-8718-903851c9899e$SxMJXAcOF0Aqs9UljAFR8'}},\n",
       " 'entity': {'createdBy': 'users/edb8841f-122e-4f7d-a412-397764bc9996',\n",
       "  'createdAt': '2024-06-11T12:53:23.376Z',\n",
       "  'updatedBy': 'users/edb8841f-122e-4f7d-a412-397764bc9996',\n",
       "  'updatedAt': '2024-06-11T12:53:23.400Z',\n",
       "  'updates': [{'operation': 'create',\n",
       "    'at': '2024-06-11T12:53:23.400Z',\n",
       "    'by': 'users/edb8841f-122e-4f7d-a412-397764bc9996',\n",
       "    'comment': '',\n",
       "    'jobs': ['740799ef-d515-4704-8718-903851c9899e$SxMJXAcOF0Aqs9UljAFR8',\n",
       "     '740799ef-d515-4704-8718-903851c9899e$OSFfqJLE9kXXLNUv45koB',\n",
       "     '740799ef-d515-4704-8718-903851c9899e$UypvDQdH-_nv6HBnogjWM']}],\n",
       "  'status': 'pending',\n",
       "  'runtime': {'deprecated': False,\n",
       "   'upgradable': False,\n",
       "   'name': 'plug-python3',\n",
       "   'version': '0.2.0'},\n",
       "  'deprecated': False,\n",
       "  'draft': False,\n",
       "  'plug': {'name': 'autoencoderV1',\n",
       "   'version': '0.0.1',\n",
       "   'runtime': 'plug-python3',\n",
       "   'metadata': {'tags': [{'name': 'MLAdapter', 'color': '#4153ea'}],\n",
       "    'documentation': {'description': '',\n",
       "     'states': [{'name': 'PREDICTED',\n",
       "       'description': 'The model inference succeeded.'},\n",
       "      {'name': 'FAILED', 'description': 'The model inference failed.'}],\n",
       "     'input': [{'name': 'instances',\n",
       "       'description': 'A tensor of numeric input data (KServe V1 protocol)'}],\n",
       "     'output': [{'name': 'predictions',\n",
       "       'description': 'A tensor of numeric output data (KServe V1 protocol)'},\n",
       "      {'name': 'error',\n",
       "       'description': 'Failure reasion when FAILED. the predictions will be empty.'}]}},\n",
       "   'type': 'sensor',\n",
       "   'interface': {'states': ['PREDICTED', 'FAILED'],\n",
       "    'input': [{'name': 'instances', 'dataType': 'object', 'mandatory': True}],\n",
       "    'output': [{'name': 'predictions',\n",
       "      'dataType': 'object',\n",
       "      'mandatory': True},\n",
       "     {'name': 'error', 'dataType': 'string', 'mandatory': False}]},\n",
       "   'deploy': {'limits': {'memory': '2G'}, 'requests': {'memory': '1G'}}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = await client.ml_tool.create_plug(adapter)\n",
    "ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b8fdd2-a364-4d6d-b773-de1407e7fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait until the build, deploy and verify jobs for the webscript have finished\n",
    "# NOTE: this might take quite a few minutes, as the dependencies for torch webscripts are quite big and the images not yet optimised\n",
    "ref = await client.ml_tool.wait_until_ready(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30353da7-0331-4dee-b09a-7de2957894df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the webscript invocation\n",
    "await client.ml_tool.test_webscript(ref, x_data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c730b-9929-49ad-bce9-242f174ebb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the webscript\n",
    "await client.ml_tool.remove(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc1aca-9fc6-4ae3-926c-8a8d0f67aa08",
   "metadata": {},
   "source": [
    "#### About `ml_tool`\n",
    "The `client.ml_tool` methods are essentialy wrappers around the methods of the [registry](https://docs.waylay.io/openapi/public/redocly/registry.html#tag/Webscripts) service. Alternatively you can use the [`client.registry.webscript`](https://github.com/waylayio/waylay-sdk-registry-py) methods directly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
